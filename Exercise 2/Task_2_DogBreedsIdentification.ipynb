{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Complete all sub-tasks marked with ## TO DO! ## and submit the filled notebook on OLAT__ \\\n",
    "__Using a GPU is recommended here__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning ###\n",
    "Aim of this notebook is to implement the concept of transfer learning to train a bigger dataset. We try to compete on a well-known competiton on Kaggle known as Dog Breeds Identification. Read more about it here:\n",
    "\n",
    "https://www.kaggle.com/c/dog-breed-identification/overview\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a model on the Dog breeds dataset using transfer learning and submit your results to Kaggle.\n",
    "Note: Below notebook gives some tips to run the code in pytorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import collections\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AlexNet import AlexNet\n",
    "from train_test import start_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "## TO DO! : Register on Kaggle With Your repective GroupName  (For example: WS19_VDL_GROUP_01)    ##\n",
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "## TO DO! : Download the Dog-Breeds dataset in folder \"data\"                                      ##\n",
    "## from the Kaggle competition link mentioned above                                               ##\n",
    "####################################################################################################\n",
    "if os.path.exists(\"./data\"):\n",
    "    os.chdir(\"data\")\n",
    "    files = [\"train.zip\", \"test.zip\"]\n",
    "    for f in files:\n",
    "        os.system(\"unzip {}\".format(f));\n",
    "    os.chdir(\"..\")\n",
    "else:\n",
    "    print(\"data folder not found\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base directory for data\n",
    "base_dir = \"./data\"\n",
    "# train, test directory relative to base directory\n",
    "train_dir = \"train\"\n",
    "test_dir = \"test\"\n",
    "# the csv file with filenames and there labels\n",
    "label_file = \"labels.csv\"\n",
    "# dictionary containing labels\n",
    "label_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "## Function to convert data into imagenet format                                                  ##\n",
    "####################################################################################################\n",
    "def convert_dataset(base_dir, label_file, train_dir):\n",
    "    try:\n",
    "        with open(os.path.join(base_dir, label_file), \"r\") as lf:\n",
    "            for line in lf:\n",
    "                line = line[:-1].split(\",\")\n",
    "                label_dict[line[0]] = line[1]\n",
    "                path = os.path.join(base_dir, train_dir, line[1])\n",
    "                if not os.path.exists(path):\n",
    "                    #make the directories for each breed\n",
    "                    os.mkdir(path)\n",
    "        lf.close()\n",
    "\n",
    "        # copy the files to the respectibe folders\n",
    "        for tf in os.listdir(os.path.join(base_dir, train_dir)):\n",
    "            if tf.split(\".\")[0] in label_dict.keys():\n",
    "                shutil.move(os.path.join(base_dir, train_dir, tf),\\\n",
    "                            os.path.join(base_dir, train_dir,\\\n",
    "                            label_dict[tf.split(\".\")[0]]))\n",
    "    except BaseException as err:\n",
    "        print(\"Error : {}\".format(err))\n",
    "            \n",
    "convert_dataset(base_dir, label_file, train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "## TO DO! : Make your dataset to and dataloaders for the  test data                                ##\n",
    "####################################################################################################\n",
    "from transform import transform_training\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root = os.path.join(base_dir, train_dir), transform=transform_training())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "## TO DO! : Split train data into 20% validation set and make dataloaders for train and val split ##\n",
    "####################################################################################################\n",
    "# train/validation split\n",
    "val_data, train_data = torch.utils.data.random_split(trainset, [2044, 8178])\n",
    "\n",
    "# create dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader =  torch.utils.data.DataLoader(val_data, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Train famous Alexnet model on Dog breeds dataset. It is not easy to train the alexnet model from \n",
    "scratch on the Dog breeds data itself. Curious minds can try for once to train Alexnet from scratch. We adopt Transfer Learning here. We \n",
    "obtain a pretrained Alexnet model trained on Imagenet and apply transfer learning to it to get better results.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "## TO DO! :  Freeze the weigths of the pretrained alexnet model and change the last classification layer\n",
    "##from 1000 classes of Imagenet to 120 classes of Dog Breeds, only classification layer should be \n",
    "## unfreezed and trainable                                                                        ##\n",
    "####################################################################################################\n",
    "import torchvision.models as models\n",
    "pretrained_alexnet = models.alexnet(pretrained=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# reinitilize the last layer to 120 to fit the number of classes\n",
    "pretrained_alexnet.classifier[6] = nn.Linear(4096, 120)\n",
    "\n",
    "# Below function will directly train your network with the given parameters to 5 epochs\n",
    "# You are also free to use function learned in task 1 to train your model here \n",
    "train_loss, test_loss = start_train_test(pretrained_alexnet, trainloader, testloader, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform import transform_testing\n",
    "import PIL.Image\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Not So optimal Code: This can take upto 2 minutes to run: You are free to make an optimal version :) ###\n",
    "# It iterates over all test images to compute the softmax probablities from the last layer of the network\n",
    "augment_image = transform_testing()\n",
    "test_data_root = 'data/dog_breeds/test/' \n",
    "test_image_list = os.listdir(test_data_root) # list of test files \n",
    "result = []\n",
    "for img_name in test_image_list:\n",
    "    img = PIL.Image.open(test_data_root + img_name)\n",
    "    img_tensor = augment_image(img)\n",
    "    with torch.no_grad():\n",
    "        output = pretrained_resnet(img_tensor.unsqueeze_(0).cuda())\n",
    "        probs = F.softmax(output, dim=1)\n",
    "    result.append(probs.cpu().numpy())\n",
    "all_predictions = np.concatenate(result)\n",
    "print(all_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_predictions)\n",
    "file_list = os.listdir('data/dog_data_imagenet/train') # list of classes to be provided here\n",
    "df.columns = sorted(file_list)\n",
    "\n",
    "# insert clean ids - without folder prefix and .jpg suffix - of images as first column\n",
    "test_data_root = 'data/dog_breeds/test/' # list of all test files here\n",
    "test_image_list = os.listdir(test_data_root)\n",
    "df.insert(0, \"id\", [e[:-4] for e in test_image_list])\n",
    "df.to_csv(f\"sub_1_alexnet.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO!: ###\n",
    "Submit the created CSV file to Kaggle, with a score(cross entropy loss) not more than __2.0__\\\n",
    "Take a snapshot of your rank on Kaggle Public Leaderboard and include the image here ...\n",
    "For example :\n",
    "![title](snp2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHALLENGE  (optional)\n",
    "Compete against each other, Come up with creative ideas. Try beating the score of __0.3__. The group with minimum score gets a small prize at the time when the solutions are discussed. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Hints:__\n",
    "\n",
    "1. Instead of Alexnet use pretrained resnet 18 model for better accuracy\n",
    "2. Instead of a just adding the last classification layer, try adding two layers to get a better loss\n",
    "3. Train some more layers at the end of the network with a very very small learning rate\n",
    "4. Add Batch Normalizations or Dropout to the layers you have added, (If not present)\n",
    "5. Add more augmentation to your dataset, see tranform.py file and use auto autoaugment to apply more rigorous data augmentation techniques"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
